{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 1: Imports\n",
    "This cell imports all necessary libraries:\n",
    "\n",
    "Standard libraries (os, pandas, numpy, json)\n",
    "Scikit-learn packages for model training, evaluation, and preprocessing\n",
    "XGBoost for gradient boosting\n",
    "Wittgenstein for the RIPPER algorithm\n",
    "SimpleImputer for handling missing values\n",
    "Warnings suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from wittgenstein import RIPPER\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, precision_recall_fscore_support,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    ")\n",
    "\n",
    "# ML models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Only suppress warnings we expect\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 2: Dataset Loading\n",
    "This cell defines and executes a function load_openml_datasets() that:\n",
    "\n",
    "Scans a directory called \"openml_datasets\" for subdirectories\n",
    "Loads CSV data files and their corresponding JSON metadata files\n",
    "Stores them in a dictionary with dataset names as keys\n",
    "Prints a summary of all 75 loaded datasets, including their shapes and available meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eadabc17b3142819a5f3da14c08337f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading datasets:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 75 datasets:\n",
      "\n",
      "Dataset: 118_BNG(mfeat-zernike,nominal,1000000)\n",
      "Data shape: (1000000, 48)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 9_autos\n",
      "Data shape: (205, 26)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 72_BNG(kr-vs-kp)\n",
      "Data shape: (1000000, 37)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 55_hepatitis\n",
      "Data shape: (155, 20)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 50_tic-tac-toe\n",
      "Data shape: (958, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 34_postoperative-patient-data\n",
      "Data shape: (90, 9)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 62_zoo\n",
      "Data shape: (101, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 23_cmc\n",
      "Data shape: (1473, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 14_mfeat-fourier\n",
      "Data shape: (2000, 77)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 16_mfeat-karhunen\n",
      "Data shape: (2000, 65)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 117_BNG(bridges_version2,nominal,1000000)\n",
      "Data shape: (1000000, 13)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 44_spambase\n",
      "Data shape: (4601, 58)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 120_BNG(mushroom)\n",
      "Data shape: (1000000, 23)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 122_BNG(colic,nominal,1000000)\n",
      "Data shape: (1000000, 23)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 36_segment\n",
      "Data shape: (2310, 20)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 71_BNG(anneal.ORIG,nominal,1000000)\n",
      "Data shape: (1000000, 39)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 75_BNG(autos,nominal,1000000)\n",
      "Data shape: (1000000, 26)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 15_breast-w\n",
      "Data shape: (699, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 28_optdigits\n",
      "Data shape: (5620, 65)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 121_BNG(colic.ORIG,nominal,1000000)\n",
      "Data shape: (1000000, 28)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 38_sick\n",
      "Data shape: (3772, 30)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 8_liver-disorders\n",
      "Data shape: (345, 6)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 46_splice\n",
      "Data shape: (3190, 61)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 2_anneal\n",
      "Data shape: (898, 39)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 27_colic\n",
      "Data shape: (368, 23)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 54_vehicle\n",
      "Data shape: (846, 19)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 30_page-blocks\n",
      "Data shape: (5473, 11)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 52_trains\n",
      "Data shape: (10, 33)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 73_BNG(labor,nominal,1000000)\n",
      "Data shape: (1000000, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 57_hypothyroid\n",
      "Data shape: (3772, 30)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 25_colic\n",
      "Data shape: (368, 27)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 78_BNG(mfeat-fourier,nominal,1000000)\n",
      "Data shape: (1000000, 77)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 76_BNG(lymph,nominal,1000000)\n",
      "Data shape: (1000000, 19)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 22_mfeat-zernike\n",
      "Data shape: (2000, 48)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 20_mfeat-pixel\n",
      "Data shape: (2000, 241)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 125_BNG(page-blocks,nominal,295245)\n",
      "Data shape: (295245, 11)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 123_BNG(optdigits)\n",
      "Data shape: (1000000, 65)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 32_pendigits\n",
      "Data shape: (10992, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 60_waveform-5000\n",
      "Data shape: (5000, 41)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 18_mfeat-morphological\n",
      "Data shape: (2000, 7)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 51_heart-h\n",
      "Data shape: (294, 14)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 11_balance-scale\n",
      "Data shape: (625, 5)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 70_BNG(anneal,nominal,1000000)\n",
      "Data shape: (1000000, 39)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 53_heart-statlog\n",
      "Data shape: (270, 14)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 126_BNG(credit-g,nominal,1000000)\n",
      "Data shape: (1000000, 21)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 6_letter\n",
      "Data shape: (20000, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 31_credit-g\n",
      "Data shape: (1000, 21)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 7_audiology\n",
      "Data shape: (226, 70)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 124_BNG(credit-a,nominal,1000000)\n",
      "Data shape: (1000000, 16)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 40_sonar\n",
      "Data shape: (208, 61)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 43_haberman\n",
      "Data shape: (306, 4)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 24_mushroom\n",
      "Data shape: (8124, 23)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 115_BNG(mfeat-karhunen,nominal,1000000)\n",
      "Data shape: (1000000, 65)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 29_credit-approval\n",
      "Data shape: (690, 16)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 10_lymph\n",
      "Data shape: (148, 19)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 26_nursery\n",
      "Data shape: (12960, 9)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 3_kr-vs-kp\n",
      "Data shape: (3196, 37)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 35_dermatology\n",
      "Data shape: (366, 35)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 5_arrhythmia\n",
      "Data shape: (452, 280)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 56_vote\n",
      "Data shape: (435, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 119_BNG(cmc,nominal,55296)\n",
      "Data shape: (55296, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 49_heart-c\n",
      "Data shape: (303, 14)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 61_iris\n",
      "Data shape: (150, 5)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 59_ionosphere\n",
      "Data shape: (351, 35)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 39_ecoli\n",
      "Data shape: (336, 8)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 77_BNG(breast-cancer,nominal,1000000)\n",
      "Data shape: (1000000, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 48_tae\n",
      "Data shape: (151, 6)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 37_diabetes\n",
      "Data shape: (768, 9)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 12_mfeat-factors\n",
      "Data shape: (2000, 217)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 42_soybean\n",
      "Data shape: (683, 36)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 116_BNG(bridges_version1,nominal,1000000)\n",
      "Data shape: (1000000, 13)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 41_glass\n",
      "Data shape: (214, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 13_breast-cancer\n",
      "Data shape: (286, 10)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 4_labor\n",
      "Data shape: (57, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n",
      "\n",
      "Dataset: 74_BNG(letter,nominal,1000000)\n",
      "Data shape: (1000000, 17)\n",
      "Meta features: ['dataset_id', 'name', 'Simple', 'Statistical', 'Information_Theoretic']...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # For progress tracking\n",
    "\n",
    "def load_openml_datasets(root_dir, lazy_load=False):\n",
    "    \"\"\"\n",
    "    Load datasets from the OpenML dataset directory structure.\n",
    "    \n",
    "    Args:\n",
    "        root_dir: Path to the root directory containing dataset folders\n",
    "        lazy_load: If True, only load metadata and load data on demand\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping dataset names to their data and metadata\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # Get all subdirectories (dataset folders)\n",
    "    dataset_dirs = [d for d in glob.glob(os.path.join(root_dir, \"*\")) \n",
    "                   if os.path.isdir(d) and os.path.basename(d) != os.path.basename(root_dir)]\n",
    "    \n",
    "    # Process each dataset directory with progress bar\n",
    "    for dataset_dir in tqdm(dataset_dirs, desc=\"Loading datasets\"):\n",
    "        dataset_name = os.path.basename(dataset_dir)\n",
    "        \n",
    "        # Find CSV and JSON files\n",
    "        csv_files = glob.glob(os.path.join(dataset_dir, \"*.csv\"))\n",
    "        json_files = glob.glob(os.path.join(dataset_dir, \"*.json\"))\n",
    "        \n",
    "        if csv_files and json_files:\n",
    "            try:\n",
    "                # Get paths\n",
    "                data_path = csv_files[0]  # Assuming the first CSV file is the main one\n",
    "                meta_path = json_files[0]  # Assuming the first JSON file has the metadata\n",
    "                \n",
    "                # Create dataset entry\n",
    "                datasets[dataset_name] = {\n",
    "                    'data_file': os.path.basename(data_path),\n",
    "                    'meta_file': os.path.basename(meta_path),\n",
    "                    'path': dataset_dir\n",
    "                }\n",
    "                \n",
    "                # Load JSON metadata\n",
    "                with open(meta_path, 'r') as f:\n",
    "                    datasets[dataset_name]['meta_features'] = json.load(f)\n",
    "                \n",
    "                # Load data if not lazy loading\n",
    "                if not lazy_load:\n",
    "                    datasets[dataset_name]['data'] = pd.read_csv(data_path)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading dataset {dataset_name}: {str(e)}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Function to get data for a dataset (used for lazy loading)\n",
    "def get_dataset_data(datasets, dataset_name):\n",
    "    \"\"\"Get the actual data for a dataset, loading it if needed.\"\"\"\n",
    "    if dataset_name not in datasets:\n",
    "        return None\n",
    "        \n",
    "    if 'data' not in datasets[dataset_name]:\n",
    "        data_path = os.path.join(datasets[dataset_name]['path'], \n",
    "                                datasets[dataset_name]['data_file'])\n",
    "        try:\n",
    "            datasets[dataset_name]['data'] = pd.read_csv(data_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {dataset_name}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    return datasets[dataset_name]['data']\n",
    "\n",
    "# Load the datasets\n",
    "openml_datasets = load_openml_datasets(dataset_root, lazy_load=False)\n",
    "\n",
    "# Print summary of loaded datasets\n",
    "print(f\"\\nLoaded {len(openml_datasets)} datasets:\")\n",
    "for name, dataset in openml_datasets.items():\n",
    "    print(f\"\\nDataset: {name}\")\n",
    "    print(f\"Data shape: {dataset['data'].shape}\")\n",
    "    print(f\"Meta features: {list(dataset['meta_features'].keys())[:5]}...\" if dataset['meta_features'] else \"No meta features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 3: Model Training Function\n",
    "This cell defines a comprehensive function train_models_on_dataset() that:\n",
    "\n",
    "Takes a dataset name and training parameters\n",
    "Preprocesses the data (handles missing values, encodes categorical features)\n",
    "Scales features using StandardScaler\n",
    "Trains seven different classification models:\n",
    "\n",
    "Logistic Regression\n",
    "Decision Tree\n",
    "Random Forest\n",
    "XGBoost\n",
    "SVM\n",
    "Neural Network (MLP)\n",
    "Gaussian Naive Bayes\n",
    "\n",
    "\n",
    "Evaluates each model and returns performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    ")\n",
    "\n",
    "def train_models_on_dataset(dataset_name, test_size=0.2, random_state=42, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Train all models on a specific dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name: Name of the dataset in openml_datasets dictionary\n",
    "        test_size: Proportion of data to use for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        n_jobs: Number of parallel jobs for models that support it\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with trained models and their performance metrics\n",
    "    \"\"\"\n",
    "    if dataset_name not in openml_datasets:\n",
    "        print(f\"Dataset {dataset_name} not found\")\n",
    "        return None\n",
    "    \n",
    "    data = openml_datasets[dataset_name]['data']\n",
    "    \n",
    "    # Assume the target is the last column (you can modify this if needed)\n",
    "    y_col = data.columns[-1]\n",
    "    X = data.drop(columns=[y_col])\n",
    "    y = data[y_col]\n",
    "    \n",
    "    # Handle missing values - separately for numeric and categorical columns\n",
    "    print(f\"  Handling missing values in dataset...\")\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = X.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = X.select_dtypes(exclude=['number']).columns\n",
    "    \n",
    "    print(f\"  Found {len(numeric_cols)} numeric columns and {len(categorical_cols)} categorical columns\")\n",
    "    \n",
    "    # Handle numeric columns with mean imputation\n",
    "    if not numeric_cols.empty:\n",
    "        numeric_imputer = SimpleImputer(strategy='mean')\n",
    "        X[numeric_cols] = numeric_imputer.fit_transform(X[numeric_cols])\n",
    "    \n",
    "    # Handle categorical columns with most frequent value imputation\n",
    "    if not categorical_cols.empty:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\n",
    "    \n",
    "    # Adjust class labels to start from 0 if needed\n",
    "    if pd.api.types.is_numeric_dtype(y):\n",
    "        if y.min() != 0:\n",
    "            print(f\"  Adjusting class labels to start from 0 (original range: {y.min()}-{y.max()})\")\n",
    "            y = y - y.min()\n",
    "\n",
    "    # Handle categorical features\n",
    "    X = pd.get_dummies(X)\n",
    "    \n",
    "    # Convert categorical target to numeric if needed\n",
    "    if not pd.api.types.is_numeric_dtype(y):\n",
    "        y = pd.factorize(y)[0]\n",
    "    \n",
    "    # Check number of classes\n",
    "    n_classes = len(np.unique(y))\n",
    "    is_binary = n_classes == 2\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, \n",
    "        stratify=y if len(np.unique(y)) < 20 else None\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize models with better parameters\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(\n",
    "            max_iter=1000, \n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs if n_jobs > 0 else None,\n",
    "            solver='saga' if X_train.shape[1] > 10000 else 'lbfgs'\n",
    "        ),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier(\n",
    "            random_state=random_state,\n",
    "            max_depth=None,  # Allow full trees\n",
    "            min_samples_split=2\n",
    "        ),\n",
    "        'RandomForestClassifier': RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs if n_jobs > 0 else None,\n",
    "            max_features='sqrt'  # More efficient for high-dimensional data\n",
    "        ),\n",
    "        'XGBClassifier': xgb.XGBClassifier(\n",
    "            n_estimators=100, \n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs if n_jobs > 0 else None,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='mlogloss' if n_classes > 2 else 'logloss'\n",
    "        ),\n",
    "        'SVC': SVC(\n",
    "            random_state=random_state, \n",
    "            max_iter=1000,\n",
    "            probability=True  # Needed for ROC AUC\n",
    "        ),\n",
    "        'MLPClassifier': MLPClassifier(\n",
    "            max_iter=500, \n",
    "            random_state=random_state,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1\n",
    "        ),\n",
    "        'GaussianNB': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    print(f\"Training models on dataset: {dataset_name}\")\n",
    "    \n",
    "    # Define a function to train a single model\n",
    "    def train_single_model(name, model, X_train, y_train, X_test, y_test, is_binary, n_classes):\n",
    "        try:\n",
    "            print(f\"  Training {name}...\")\n",
    "            \n",
    "            # Special handling for XGBoost with early stopping\n",
    "            if name == 'XGBClassifier':\n",
    "                X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "                    X_train_scaled, y_train, test_size=0.2, random_state=random_state\n",
    "                )\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    verbose=False\n",
    "                )\n",
    "            else:\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                \n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate metrics based on problem type\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # For multiclass problems\n",
    "            precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            \n",
    "            # ROC AUC - handle binary vs multiclass\n",
    "            roc_auc = None\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = model.predict_proba(X_test_scaled)\n",
    "                if is_binary:\n",
    "                    # For binary classification\n",
    "                    roc_auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "                elif n_classes > 2:\n",
    "                    # For multiclass, use OVR approach\n",
    "                    try:\n",
    "                        roc_auc = roc_auc_score(\n",
    "                            np.eye(n_classes)[y_test], \n",
    "                            y_proba,\n",
    "                            multi_class='ovr'\n",
    "                        )\n",
    "                    except:\n",
    "                        roc_auc = None\n",
    "            \n",
    "            # Log loss if available\n",
    "            log_loss_value = None\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                try:\n",
    "                    log_loss_value = log_loss(y_test, y_proba)\n",
    "                except:\n",
    "                    log_loss_value = None\n",
    "            \n",
    "            result = {\n",
    "                'model': model,\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'roc_auc': roc_auc,\n",
    "                'log_loss': log_loss_value,\n",
    "                'predictions': y_pred\n",
    "            }\n",
    "            \n",
    "            print(f\"    Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, Log Loss: {log_loss_value:.4f if log_loss_value else 'N/A'}\")\n",
    "            return name, result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error training {name}: {str(e)}\")\n",
    "            return name, {'error': str(e)}\n",
    "    \n",
    "    # Train models (sequentially for better notebook output)\n",
    "    for name, model in models.items():\n",
    "        model_name, model_results = train_single_model(\n",
    "            name, model, X_train_scaled, y_train, X_test_scaled, y_test, is_binary, n_classes\n",
    "        )\n",
    "        results[model_name] = model_results\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 4: Results Saving Function\n",
    "This cell defines a function save_results_to_csv() that:\n",
    "\n",
    "Takes model performance results and a dataset name\n",
    "Formats the results into a DataFrame\n",
    "Saves the DataFrame to a CSV file named \"[dataset_name]_model_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def save_results_to_csv(results, dataset_name, include_timestamp=True):\n",
    "    \"\"\"\n",
    "    Save model performance results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        results (dict): Dictionary with trained models and their performance metrics.\n",
    "        dataset_name (str): Name of the dataset used for training.\n",
    "        include_timestamp (bool): Whether to include a timestamp in the filename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create data rows\n",
    "        data = []\n",
    "        for model_name, metrics in results.items():\n",
    "            if 'error' in metrics:  # If model training failed\n",
    "                data.append([model_name, 'Error', 'Error', 'Error', 'Error', 'Error', 'Error'])\n",
    "            else:\n",
    "                # Use `.get()` to handle missing keys safely\n",
    "                data.append([\n",
    "                    model_name, \n",
    "                    metrics.get('accuracy', 'N/A'), \n",
    "                    metrics.get('precision', 'N/A'), \n",
    "                    metrics.get('recall', 'N/A'), \n",
    "                    metrics.get('f1_score', 'N/A'), \n",
    "                    metrics.get('roc_auc', 'N/A'),\n",
    "                    metrics.get('log_loss', 'N/A')\n",
    "                ])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC AUC', 'Log Loss'])\n",
    "\n",
    "        # Add timestamp if requested\n",
    "        timestamp = \"\"\n",
    "        if include_timestamp:\n",
    "            timestamp = f\"_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        # Save to CSV\n",
    "        filename = f\"{dataset_name}{timestamp}_model_results.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "        print(f\"Results saved to {filename}\")\n",
    "        return filename\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 5: Single Dataset Training and Saving\n",
    "This cell:\n",
    "\n",
    "Runs the training function on a specific dataset ('16_mfeat-karhunen')\n",
    "Saves the results to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with dataset: 16_mfeat-karhunen\n",
      "  Handling missing values in dataset...\n",
      "  Found 64 numeric columns and 0 categorical columns\n",
      "  Adjusting class labels to start from 0 (original range: 1-10)\n",
      "Training models on dataset: 16_mfeat-karhunen\n",
      "  Training LogisticRegression...\n",
      "    Error training LogisticRegression: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "  Training DecisionTreeClassifier...\n",
      "    Error training DecisionTreeClassifier: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "  Training RandomForestClassifier...\n",
      "    Error training RandomForestClassifier: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "  Training XGBClassifier...\n",
      "    Error training XGBClassifier: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "  Training SVC...\n",
      "    Error training SVC: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "  Training MLPClassifier...\n",
      "    Error training MLPClassifier: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "  Training GaussianNB...\n",
      "    Error training GaussianNB: Invalid format specifier '.4f if log_loss_value else 'N/A'' for object of type 'float'\n",
      "Results saved to 16_mfeat-karhunen_20250312_203813_model_results.csv\n",
      "\n",
      "=== SUMMARY FOR 16_mfeat-karhunen ===\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Choose a specific dataset by name\n",
    "test_dataset = \"16_mfeat-karhunen\"\n",
    "print(f\"Testing with dataset: {test_dataset}\")\n",
    "\n",
    "# Run the training function\n",
    "results = train_models_on_dataset(test_dataset)\n",
    "\n",
    "# Save results to CSV\n",
    "csv_filename = save_results_to_csv(results, test_dataset)\n",
    "\n",
    "# Print summary for this dataset\n",
    "print(f\"\\n=== SUMMARY FOR {test_dataset} ===\")\n",
    "accuracies = {name: res['accuracy'] for name, res in results.items() if 'accuracy' in res}\n",
    "\n",
    "if accuracies:\n",
    "    best_model = max(accuracies.items(), key=lambda x: x[1])\n",
    "    print(f\"  Best model: {best_model[0]} (Accuracy: {best_model[1]:.4f})\")\n",
    "    \n",
    "    print(\"  All models:\")\n",
    "    for model_name, accuracy in sorted(accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"    {model_name}: {accuracy:.4f}\")\n",
    "\n",
    "    # Visualize the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    sorted_models = sorted(accuracies.items(), key=lambda x: x[1], reverse=True)\n",
    "    plt.barh([name for name, _ in sorted_models], [acc for _, acc in sorted_models])\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Model')\n",
    "    plt.title(f'Model Accuracy Comparison - {test_dataset}')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    for i, (_, acc) in enumerate(sorted_models):\n",
    "        plt.text(acc + 0.01, i, f'{acc:.4f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 6: Test Run with Performance Summary\n",
    "This cell:\n",
    "\n",
    "Runs the training function again on the same dataset ('16_mfeat-karhunen')\n",
    "Prints a summary of the results, showing each model's accuracy\n",
    "Identifies the best performing model (in this case, SVC and MLPClassifier tied at 97% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with dataset: BNG(lymph,nominal,1000000)\n",
      "Dataset BNG(lymph,nominal,1000000) not found\n",
      "\n",
      "=== SUMMARY FOR BNG(lymph,nominal,1000000) ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Print summary for this dataset\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m=== SUMMARY FOR \u001b[39m\u001b[39m{\u001b[39;00mtest_dataset\u001b[39m}\u001b[39;00m\u001b[39m ===\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m accuracies \u001b[39m=\u001b[39m {name: res[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m name, res \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m res}\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m accuracies:\n\u001b[1;32m     13\u001b[0m     best_model \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(accuracies\u001b[39m.\u001b[39mitems(), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Choose a specific dataset by name\n",
    "test_dataset = \"BNG(lymph,nominal,1000000)\"  # Replace \"iris\" with the actual name of your dataset\n",
    "print(f\"Testing with dataset: {test_dataset}\")\n",
    "\n",
    "# Run the training function on just this dataset\n",
    "results = train_models_on_dataset(test_dataset)\n",
    "\n",
    "# Print summary for this dataset\n",
    "print(f\"\\n=== SUMMARY FOR {test_dataset} ===\")\n",
    "accuracies = {name: res['accuracy'] for name, res in results.items() if 'accuracy' in res}\n",
    "\n",
    "if accuracies:\n",
    "    best_model = max(accuracies.items(), key=lambda x: x[1])\n",
    "    print(f\"  Best model: {best_model[0]} (Accuracy: {best_model[1]:.4f})\")\n",
    "    \n",
    "    print(\"  All models:\")\n",
    "    for model_name, accuracy in sorted(accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"    {model_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell 7: Batch Processing (Commented Out)\n",
    "This cell contains code to:\n",
    "\n",
    "Train models on all datasets in the collection\n",
    "Generate a comprehensive summary of results across all datasets\n",
    "The cell is not executed (no output shown) and likely would take a long time to run given the large number of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "for dataset_name in openml_datasets.keys():\n",
    "    print(f\"\\n=== Dataset: {dataset_name} ===\")\n",
    "    all_results[dataset_name] = train_models_on_dataset(dataset_name)\n",
    "\n",
    "print(\"\\n=== SUMMARY OF RESULTS ===\")\n",
    "for dataset_name, results in all_results.items():\n",
    "    print(f\"\\nDataset: {dataset_name}\")\n",
    "    accuracies = {name: res['accuracy'] for name, res in results.items() if 'accuracy' in res}\n",
    "    \n",
    "    if accuracies:\n",
    "        best_model = max(accuracies.items(), key=lambda x: x[1])\n",
    "        print(f\"  Best model: {best_model[0]} (Accuracy: {best_model[1]:.4f})\")\n",
    "        \n",
    "        print(\"  All models:\")\n",
    "        for model_name, accuracy in sorted(accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {model_name}: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
